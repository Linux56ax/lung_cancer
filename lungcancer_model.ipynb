{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2109d453",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os, math, sys, time\n",
    "import pandas as pd, numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, f1_score\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69d16dc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Paths\n",
    "DATA_PATH = \"dataset_med.csv\"\n",
    "BEST_MODEL_PATH = \"best_lung_cancer_model.pth\"\n",
    "CM_IMAGE_PATH = \"lung_confusion_matrix.png\"\n",
    "\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print(\"Loaded dataset:\", DATA_PATH, \"shape:\", df.shape)\n",
    "\n",
    "# Drop id if present\n",
    "if 'id' in df.columns:\n",
    "    df = df.drop(columns=['id'])\n",
    "\n",
    "# Handle date columns if present\n",
    "if 'diagnosis_date' in df.columns and 'end_treatment_date' in df.columns:\n",
    "    df['diagnosis_date'] = pd.to_datetime(df['diagnosis_date'], errors='coerce')\n",
    "    df['end_treatment_date'] = pd.to_datetime(df['end_treatment_date'], errors='coerce')\n",
    "    df['treatment_duration'] = (df['end_treatment_date'] - df['diagnosis_date']).dt.days.fillna(0)\n",
    "    df['diagnosis_month'] = df['diagnosis_date'].dt.month.fillna(0).astype(int)\n",
    "    df = df.drop(columns=['diagnosis_date', 'end_treatment_date'])\n",
    "\n",
    "# Identify numerical and categorical\n",
    "numerical_cols = df.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "# Ensure target column 'survived' exists\n",
    "if 'survived' not in df.columns:\n",
    "    raise ValueError(\"Target column 'survived' not found in dataset. Please ensure the CSV contains 'survived'.\")\n",
    "\n",
    "# Exclude target from numerical list\n",
    "if 'survived' in numerical_cols:\n",
    "    numerical_cols.remove('survived')\n",
    "\n",
    "# Fill missing values\n",
    "for col in numerical_cols:\n",
    "    df[col] = df[col].fillna(df[col].median())\n",
    "for col in categorical_cols:\n",
    "    df[col] = df[col].fillna(df[col].mode().iloc[0] if not df[col].mode().empty else \"\")\n",
    "\n",
    "# Label encode categorical columns\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6846e912",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Feature engineering as in script\n",
    "if \"bmi\" in df.columns and \"age\" in df.columns:\n",
    "    df[\"bmi_age_ratio\"] = df[\"bmi\"] / (df[\"age\"].replace(0, np.nan))\n",
    "    df[\"bmi_age_ratio\"] = df[\"bmi_age_ratio\"].fillna(df[\"bmi_age_ratio\"].median())\n",
    "\n",
    "if \"cancer_stage\" in df.columns and \"treatment_type\" in df.columns:\n",
    "    df[\"stage_treatment_interaction\"] = df[\"cancer_stage\"] * df[\"treatment_type\"]\n",
    "\n",
    "medical_conditions = ['hypertension', 'asthma', 'cirrhosis', 'other_cancer']\n",
    "if all(col in df.columns for col in medical_conditions):\n",
    "    df['risk_score'] = df[medical_conditions].sum(axis=1)\n",
    "\n",
    "# Prepare X and y\n",
    "X = df.drop(columns=['survived'])\n",
    "y = df['survived'].astype(int)\n",
    "\n",
    "# Feature selection via mutual info (handle cases where features < 12)\n",
    "try:\n",
    "    mi_scores = mutual_info_classif(X, y, discrete_features='auto', random_state=42)\n",
    "    feature_importance = pd.DataFrame({'feature': X.columns, 'importance': mi_scores})\n",
    "    feature_importance = feature_importance.sort_values('importance', ascending=False)\n",
    "    top_k = min(12, X.shape[1])\n",
    "    top_features = feature_importance['feature'].head(top_k).tolist()\n",
    "    X = X[top_features]\n",
    "except Exception as e:\n",
    "    # fallback: use all features\n",
    "    print(\"Mutual info failed:\", e)\n",
    "    top_features = X.columns.tolist()\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "\n",
    "print(\"Using features:\", X_scaled.columns.tolist())\n",
    "\n",
    "# Convert to numpy for indexing\n",
    "X_np = X_scaled.reset_index(drop=True)\n",
    "y_np = y.reset_index(drop=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Define model\n",
    "class EnhancedLungCancerPredictor(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.batch_norm1 = nn.BatchNorm1d(input_dim)\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1)\n",
    "        )\n",
    "        self.output = nn.Linear(64, 1)\n",
    "    def forward(self, x):\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        return self.output(x)\n",
    "\n",
    "# Training params (reduced epochs to 30 for practical runtime)\n",
    "n_splits = 7\n",
    "epochs = 25\n",
    "batch_size = 128\n",
    "best_overall_auc = 0.0\n",
    "best_model_state = None\n",
    "fold_metrics = []\n",
    "\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_np, y_np)):\n",
    "    print(f\"\\n--- Fold {fold} ---\")\n",
    "    X_train = torch.FloatTensor(X_np.iloc[train_idx].values).to(device)\n",
    "    y_train = torch.FloatTensor(y_np.iloc[train_idx].values).reshape(-1,1).to(device)\n",
    "    X_val = torch.FloatTensor(X_np.iloc[val_idx].values).to(device)\n",
    "    y_val = torch.FloatTensor(y_np.iloc[val_idx].values).reshape(-1,1).to(device)\n",
    "    \n",
    "    model = EnhancedLungCancerPredictor(X_train.shape[1]).to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "    \n",
    "    best_val_auc = 0.0\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        perm = torch.randperm(X_train.size(0))\n",
    "        epoch_loss = 0.0\n",
    "        for i in range(0, X_train.size(0), batch_size):\n",
    "            idx = perm[i:i+batch_size]\n",
    "            batch_X = X_train[idx]\n",
    "            batch_y = y_train[idx]\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item() * batch_X.size(0)\n",
    "        epoch_loss = epoch_loss / X_train.size(0)\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_outputs = model(X_val)\n",
    "            val_loss = criterion(val_outputs, y_val)\n",
    "            val_probs = torch.sigmoid(val_outputs).cpu().numpy()\n",
    "            val_preds = (val_probs > 0.5).astype(int)\n",
    "            val_auc = roc_auc_score(y_val.cpu().numpy(), val_probs)\n",
    "            val_acc = accuracy_score(y_val.cpu().numpy(), val_preds)\n",
    "        scheduler.step(val_loss)\n",
    "        if val_auc > best_val_auc:\n",
    "            best_val_auc = val_auc\n",
    "            torch.save(model.state_dict(), f\"best_model_fold_{fold}.pth\")\n",
    "        if (epoch+1) % 10 == 0 or epoch==0:\n",
    "            print(f\"Epoch {epoch+1}/{epochs} - loss: {epoch_loss:.4f} - val_auc: {val_auc:.4f} - val_acc: {val_acc:.4f}\")\n",
    "    \n",
    "    # Load best for this fold and evaluate\n",
    "    model.load_state_dict(torch.load(f\"best_model_fold_{fold}.pth\", map_location=device))\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_outputs = model(X_val)\n",
    "        val_probs = torch.sigmoid(val_outputs).cpu().numpy().reshape(-1)\n",
    "        val_preds = (val_probs > 0.5).astype(int)\n",
    "        acc = accuracy_score(y_val.cpu().numpy(), val_preds)\n",
    "        auc = roc_auc_score(y_val.cpu().numpy(), val_probs)\n",
    "        f1 = f1_score(y_val.cpu().numpy(), val_preds)\n",
    "        cm = confusion_matrix(y_val.cpu().numpy(), val_preds)\n",
    "    fold_metrics.append({'fold': fold, 'accuracy': acc, 'auc': auc, 'f1': f1, 'confusion_matrix': cm})\n",
    "    print(f\"Fold {fold} -> Accuracy: {acc:.4f}, AUC: {auc:.4f}, F1: {f1:.4f}\")\n",
    "    \n",
    "    # track global best\n",
    "    if auc > best_overall_auc:\n",
    "        best_overall_auc = auc\n",
    "        best_model_state = torch.load(f\"best_model_fold_{fold}.pth\", map_location=device)\n",
    "        best_confusion = cm.copy()\n",
    "        best_fold = fold\n",
    "\n",
    "# Save best overall model\n",
    "if best_model_state is not None:\n",
    "    torch.save(best_model_state, BEST_MODEL_PATH)\n",
    "    print(\"Saved best overall model to\", BEST_MODEL_PATH)\n",
    "\n",
    "# Aggregate metrics\n",
    "metrics_df = pd.DataFrame([{'fold': m['fold'], 'accuracy': m['accuracy'], 'auc': m['auc'], 'f1': m['f1']} for m in fold_metrics])\n",
    "metrics_df.loc['mean'] = metrics_df.mean(numeric_only=True)\n",
    "print(\"\\nPer-fold metrics:\\n\", metrics_df)\n",
    "\n",
    "# Plot confusion matrix for best fold\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(best_confusion, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title(f'Confusion Matrix (Best Fold {best_fold})')\n",
    "plt.tight_layout()\n",
    "plt.savefig(CM_IMAGE_PATH)\n",
    "plt.show()\n",
    "print(\"Saved confusion matrix image to\", CM_IMAGE_PATH)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
